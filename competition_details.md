# 📝 比賽技術細節報告 | Soaring Stock Prediction

## 🙋 我的貢獻

身為本次比賽的隊長，我負責 **整體策略規劃** 與 **SOP 設計**。  
我提出以「交集/差集模型」為核心的流程，解決 **特徵過濾** 與 **模型多樣性** 問題。  
同時建立的 **精簡模型（23 特徵）** 在融合架構中發揮關鍵貢獻，  
並設計 **反向驗證**，證明未被選取的變數對預測幾乎無影響，  
確保 SOP 的**完整性與可靠性**，最終協助團隊進入 **Top 3%**。  


## 📚 內容導覽

- [1. 賽題簡介](#1-賽題簡介)
- [2. 資料特性與前處理](#2-資料特性與前處理)
- [3. 特徵選擇策略](#3-特徵選擇策略)
- [4. 模型設計](#4-模型設計)
- [5. 模型融合與預測策略](#5-模型融合與預測策略)
- [6. 模型成效與 Leaderboard 結果](#6-模型成效與-leaderboard-結果)
- [7. 模型建構上的挑戰與策略](#7-模型建構上的挑戰與策略)
- [8. 最終成績與排名](#8-最終成績與排名)

## 1. 賽題簡介
本比賽旨在預測「潛在飆股」之出現與否，屬於二元分類問題，標記為 1 的飆股比例極低，具有高度不平衡性。預測模型須能有效識別出極少數關鍵樣本，對 recall 要求相對較高。

> 📌 本檔案僅記錄技術流程，資料內容因比賽規範不予公開。
---

## 2. 資料特性與前處理

### 📌 資料特性
- 擁有 **上萬個解釋變數**（高維特徵）
- 含有 **大量缺失值**，特定欄位缺值比例極高
- 類別不平衡問題嚴重（標記為 1 的飆股樣本極少）

### 🔧 前處理流程
- **資料切分**：
  - 訓練資料（Training set）：60%
  - 驗證資料 (Validation set)：20%
  - 測試資料（Testing set）：20%
  - 使用 stacking 時會使用到Testing set
- **缺失值處理**：主要採用 **中位數補值**。亦曾嘗試 KNN 補值，惟處理時間長、效果差異不大，因此最終選擇中位數補值作為預設策略。
- **類別不平衡處理**：於建模階段考慮使用 SMOTE、ADASYN 等重抽樣技術（細節見建模章節）

---

## 3. 特徵選擇策略

原始資料包含超過一萬個特徵。為降低計算負擔並提升模型穩定性，本研究設計了多階段特徵篩選流程：

### 🔹 步驟一：關鍵字過濾
- 初步觀察發現，**重要變數常帶有特定關鍵字**  
- 結合 domain knowledge 設計六組關鍵字過濾器，將特徵數量由 **10,000+ 壓縮至約 5,000**

### 🔹 步驟二：XGBoost 與 Permutation Importance
- 從訓練資料中**隨機抽樣 50%** 進行特徵篩選  
- 採用兩種方法：
  - `XGBoost` feature importance  
  - `Permutation importance`

### 🔹 步驟三：交集特徵選取
- **Permutation importance** 在強烈共線下會刪除冗餘特徵，因此直接將步驟一篩出的變數輸入其中  
- **XGBoost importance** 則容易保留共線性特徵，因此將步驟一的關鍵字進一步精簡（由六個縮減為五個），以提升效果  
- 兩方法最終各自選出約 **110 個（XGB）** 與 **128 個（Permutation）** 特徵  
- 取其**交集**後，得到 **23 個核心解釋變數**  
- 值得注意的是，交集僅佔各方法約 **20%**，但以此子集訓練模型仍具良好表現，顯示交集策略的必要性  
- 另外也曾嘗試直接以步驟一的重要變數分別跑兩種方法，再取交集，約得到 **50 個變數**，但模型效果反而下降，突顯**關鍵字數量設定的影響**  

---

## 4. 模型設計

### 🧪 類別不平衡處理
由於飆股樣本極少，為提升模型辨識能力，訓練階段採用了 **ADASYN**（Adaptive Synthetic Sampling）進行再平衡處理。設定 `sampling_strategy = 0.5`，即將少數類別樣本比例提升至佔整體的 50%，在兼顧 recall 的同時避免過度生成樣本。

本專案主要使用 `XGBoost` 作為核心模型。選擇該模型的原因如下：

### ✅ 模型選擇理由
- `XGBoost` 在 Python 環境下擁有高度最佳化的實作，訓練速度相對其他樹模型更快
- 可處理大量特徵與缺失值，並內建正則化機制以防止過擬合
- 實務上表現穩定，適合用於此類特徵工程導向任務

### ⚙️ 調參策略
- 使用 `GridSearchCV` 進行交叉驗證，搜尋以下重要超參數：
- **正則化處理**透過 `reg_alpha`、`reg_lambda` 控制模型複雜度
- **類別權重**動態設定 `scale_pos_weight`，以處理類別不平衡問題：
- 模型表現依據驗證資料的 macro F1-score 評估

### 💡 其他模型考量
- 雖曾嘗試使用 `LightGBM`，但在相同資料與硬體環境下訓練時間較長
- 實驗結果顯示 `XGBoost` 在精度與效率間取得良好平衡，最終採用為主力模型

> 🧠 若有更多時間與資源，未來可進一步比較 `CatBoost`、`LGBM` 等模型在不平衡資料下的表現。

### 分類閾值（Threshold）優化策略
- 閾值搜尋：透過驗證資料（Validation set），遍歷一系列候選閾值，計算對應 F1-score
- 最佳閾值選取：選出使驗證資料 F1-score 最大化的 threshold 值
- 模型再訓練：將訓練資料與驗證資料合併，使用相同參數重新訓練最終模型
- 最終預測：於測試資料上套用最佳 threshold，進行預測並評估成效

--- 
## 5. 模型融合與預測策略

為進一步提升模型穩定性與泛化能力，本專案採用 **Stacking** 方法結合多個基礎模型的預測結果。這是因為單一模型難以全面捕捉所有資料特性，容易在部分樣本上出現誤判，融合策略可望整合不同模型之優勢。

### 🧱 Stacking 架構

- **第一層（Base models）**：使用多個具代表性的模型（如 XGBoost、LightGBM、其他實驗性模型）對樣本進行預測，並收集其預測機率作為第二層輸入。
- **第二層（Meta-model）**：使用簡單的邏輯斯回歸（Logistic Regression）作為融合模型，預測最終結果。

### 🔧 模型選擇與實驗結果

- 雖曾嘗試使用 **Random Forest** 作為第二層模型，亦實驗過 **Backward Selection** 機制以過濾表現不佳的基礎模型，最終結果顯示：
  - **簡單的 Logistic Regression** 具備良好泛化能力與穩定性
  - 在保留模型解釋性的同時，表現亦優於其他融合策略

### 🧪 測試資料的再利用方式

- 由於本專案設計中，**測試資料僅用於最終評估，不參與單一模型訓練**
- 因此，部分測試資料可被分配至 stacking 的第二層訓練，以補充 meta-model 的樣本資訊，**在不破壞原始訓練流程的前提下提升融合表現**

> 💡 此策略兼顧實務應用與準確率最大化，並維持測試資料的完整獨立性，避免資料外洩。

---

## 6. 模型成效與 Leaderboard 結果

| 模型類型        | 特徵數 | Macro F1 (Public) | Leaderboard (Private)      |
|------------------|--------|-------------------|-----------------------------|
| 精簡模型         | 23     | 0.801             | 未提交（Private leaderboard 僅提交融合模型結果）         |
| 融合模型（Best） | 5000+（全組員 stacking） | 0.837             | Top 3%           |

雖然精簡模型（僅使用 23 個變數）並未提交至 Private leaderboard，但其在 Public leaderboard 上的 Macro F1-score 已達 **0.801**，與最終融合模型（0.837）相差不大。

### ⏱ 訓練效率比較
- 精簡模型訓練時間僅為融合模型的 **1/20**
- 大幅減少運算資源與模型調參時間，適合快速部署或資源有限的應用場景

### 🧠 特徵解釋性與實用性
- **精簡模型能有效捕捉主要影響飆股的關鍵特徵**，而融合模型無法
- 在效率與預測表現之間取得良好平衡，也**提升模型可解釋性**

### 🤝 融合模型中的貢獻與觀察
值得一提的是，**精簡模型本身亦被納入最終的融合模型中**，並在 meta-model（如 Logistic Regression）中展現出高度影響力。實驗發現：

- 融合模型中多數基礎模型對應的係數較小，但精簡模型的預測結果在 meta-model 中被賦予明顯更高的權重
- 表示即使在大型特徵集下，**經精選的 23 個變數模型仍具關鍵預測力**，能提供額外且穩定的資訊

> 💡 結論：融合模型雖整體表現最佳，但精簡模型在資訊貢獻、效率與泛化能力上皆具亮點，為未來實務應用提供高效可行的方案。

---

## 7. 模型建構上的挑戰與策略

本次競賽主要面臨兩大核心挑戰，以及一個延伸挑戰：

### 🧩 挑戰一：特徵數量龐大、關鍵訊息稀少
- 原始特徵數超過一萬，但真正與飆股高度相關的變數極為有限  
- 傳統特徵選擇方法難以有效濾出**穩定且具泛化力**的特徵組合  

### 🔀 挑戰二：Stacking 效果受限於模型同質性
- Stacking 的效果仰賴多個基模型之間的高度互補性  
- 由於組內密集討論與策略交流，模型架構與特徵選擇趨於一致，導致融合增益有限  

### 📌 延伸挑戰：如何確保關鍵變數不被遺漏
- 面對上萬個特徵，透過兩種特徵選擇方法（XGBoost 與 Permutation importance）最終僅保留約 **200 個特徵（聯集）**，其中交集模型更僅剩 **23 個**  
- 需要進一步驗證：**被排除的特徵是否確實不具重要性**，以避免遺漏潛在關鍵因子  

---

## ✅ 解法：SOP 設計以同時解決兩個問題

我設計了一套分析 SOP，旨在一次性解決「特徵選擇」與「模型多樣性不足」的問題，具體策略如下：

### Step 1️⃣ 雙方法特徵選擇 → 取交集建 Model 1
- 使用 **XGBoost Importance** 與 **Permutation Importance** 得到兩組關鍵變數集合
- 取兩者交集，共得 **23 個變數**，構建 **Model 1**
- 測試資料上 F1-score 約為 **0.84**

### Step 2️⃣ 差集建模 → 擴展模型差異性
- 將兩集合的差集（A \ B、B \ A）分別建構 **Model 2**、**Model 3**
- 各模型使用變數約 100 個，F1-score 約為 **0.65**
- 三個模型變數**兩兩互斥**，自然具備高度結構差異性，有助於 Stacking 效果提升

### Step 3️⃣ 融合建模
- 將 Model 1~3 進行 Stacking 融合
- 僅使用約 200 個變數，即可達到 Public F1-score **約 0.82**
- 效能接近最好的融合模型（F1 ≈ 0.83），但模型結構更簡潔、訓練更有效率


## 🔍 特徵完整性驗證：是否有遺漏關鍵變數？

為進一步驗證特徵選擇的完整性，我設計反向驗證策略：

- 將上述三個模型未涵蓋的所有剩餘變數（約 9800+）作為特徵，構建 **Model 4**
- 即測試「被排除的變數是否仍蘊含有用資訊」
- 結果顯示 Model 4 在測試資料上僅達 **F1-score ≈ 0.05**

---
  
### ✅ 結論
- 幾乎所有關鍵變數已被成功挑選與納入
- 未被選取的特徵對預測飆股貢獻極小，證明 SOP 策略具備高準確性與有效性

> 💡 此策略同時解決高維特徵過濾與 stacking 模型相似性問題，展現良好的方法設計與驗證邏輯，具備高度可重現性與擴展性。
 
---

## 8. 最終成績與排名

| Public Macro F1 | Private Macro F1 | Private Leaderboard |
|------------------|-------------------|----------------------|
| **0.8366**        | **0.8262**         | Top **3%**           |

本專案最終在Public Data上達成 **0.8366** 的 Macro F1，在Private Data上亦有穩定表現，Macro F1 為 **0.8262**，總成績穩居 Private Leaderboard 的前 **3%**。

> 🎯 模型整體兼顧精度、效率與解釋性，展現出良好的實務應用潛力。



