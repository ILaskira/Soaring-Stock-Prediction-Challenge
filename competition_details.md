# 📝 比賽技術細節報告 | Soaring Stock Prediction

## 1. 賽題簡介
本比賽旨在預測「潛在飆股」之出現與否，屬於二元分類問題，標記為 1 的飆股比例極低，具有高度不平衡性。預測模型須能有效識別出極少數關鍵樣本，對 recall 要求相對較高。

---

## 2. 資料特性與前處理

### 📌 資料特性
- 擁有 **上萬個解釋變數**（高維特徵）
- 含有 **大量缺失值**，特定欄位缺值比例極高
- 類別不平衡問題嚴重（標記為 1 的飆股樣本極少）

### 🔧 前處理流程
- **資料切分**：
  - 訓練資料（Training set）：60%
  - 驗證資料 (Validation set)：20%
  - 測試資料（Testing set）：20%
  - 使用 stacking 時會使用到Testing set
- **缺失值處理**：- 主要採用 **中位數補值**。亦曾嘗試 KNN 補值，惟處理時間長、效果差異不大，因此最終選擇中位數補值作為預設策略。
- **類別不平衡處理**：於建模階段考慮使用 SMOTE、ADASYN 等重抽樣技術（細節見建模章節）

---

## 3. 特徵選擇策略

由於原始資料擁有超過一萬個特徵，為避免計算負擔並提升模型穩定性，採用以下多階段特徵篩選流程：

### 🔹 第一步：關鍵字過濾
- 初步觀察後發現，**重要變數多包含特定關鍵字**
- 透過 domain knowledge 設計關鍵字過濾器，初步將特徵數量由 **10,000+ 降至約 5,000**

### 🔹 第二步：XGBoost & Permutation Importance
- 從訓練資料中**隨機抽取 50% 樣本進行特徵選擇**
- 分別使用：
  - `XGBoost` feature importance
  - `Permutation importance`

### 🔹 第三步：選擇交集特徵
- 前兩者各自選出前 200 名重要特徵
- 發現 XGBoost 偏向選取共線特徵，Permutation 有更強過濾能力（選出約 120 個特徵）
- 最終取兩者選出的特徵**交集**作為穩定代表，得到 **23 個核心解釋變數**

---

## 4. 模型設計

### 🧪 類別不平衡處理
由於飆股樣本極少，為提升模型辨識能力，訓練階段採用了 **ADASYN**（Adaptive Synthetic Sampling）進行再平衡處理。設定 `sampling_strategy = 0.5`，即將少數類別樣本比例提升至佔整體的 50%，在兼顧 recall 的同時避免過度生成樣本。

本專案主要使用 `XGBoost` 作為核心模型。選擇該模型的原因如下：

### ✅ 模型選擇理由
- `XGBoost` 在 Python 環境下擁有高度最佳化的實作，訓練速度相對其他樹模型更快
- 可處理大量特徵與缺失值，並內建正則化機制以防止過擬合
- 實務上表現穩定，適合用於此類特徵工程導向任務

### ⚙️ 調參策略
- 使用 `GridSearchCV` 進行交叉驗證，搜尋以下重要超參數：
- **正則化處理**透過 `reg_alpha`、`reg_lambda` 控制模型複雜度
- **類別權重**動態設定 `scale_pos_weight`，以處理類別不平衡問題：
- 模型表現依據驗證資料的 macro F1-score 評估

### 💡 其他模型考量
- 雖曾嘗試使用 `LightGBM`，但在相同資料與硬體環境下訓練時間較長
- 實驗結果顯示 `XGBoost` 在精度與效率間取得良好平衡，最終採用為主力模型

> 🧠 若有更多時間與資源，未來可進一步比較 `CatBoost`、`LGBM` 等模型在不平衡資料下的表現。

### 分類閾值（Threshold）優化策略
- 閾值搜尋：透過驗證資料（Validation set），遍歷一系列候選閾值，計算對應 F1-score
- 最佳閾值選取：選出使驗證資料 F1-score 最大化的 threshold 值
- 模型再訓練：將訓練資料與驗證資料合併，使用相同參數重新訓練最終模型
- 最終預測：於測試資料上套用最佳 threshold，進行預測並評估成效

--- 
## 5. 模型融合與預測策略

為進一步提升模型穩定性與泛化能力，本專案採用 **Stacking** 方法結合多個基礎模型的預測結果。這是因為單一模型難以全面捕捉所有資料特性，容易在部分樣本上出現誤判，融合策略可望整合不同模型之優勢。

### 🧱 Stacking 架構

- **第一層（Base models）**：使用多個具代表性的模型（如 XGBoost、LightGBM、其他實驗性模型）對樣本進行預測，並收集其預測機率作為第二層輸入。
- **第二層（Meta-model）**：使用簡單的邏輯斯回歸（Logistic Regression）作為融合模型，預測最終結果。

### 🔧 模型選擇與實驗結果

- 雖曾嘗試使用 **Random Forest** 作為第二層模型，亦實驗過 **Backward Selection** 機制以過濾表現不佳的基礎模型，最終結果顯示：
  - **簡單的 Logistic Regression** 具備良好泛化能力與穩定性
  - 在保留模型解釋性的同時，表現亦優於其他融合策略

### 🧪 測試資料的再利用方式

- 由於本專案設計中，**測試資料僅用於最終評估，不參與單一模型訓練**
- 因此，部分測試資料可被分配至 stacking 的第二層訓練，以補充 meta-model 的樣本資訊，**在不破壞原始訓練流程的前提下提升融合表現**

> 💡 此策略兼顧實務應用與準確率最大化，並維持測試資料的完整獨立性，避免資料外洩。


## 6. 評估與 leaderboard 結果
| 模型 | 特徵數 | Macro F1 | Leaderboard |
|------|--------|----------|-------------|
| 精簡模型 | 23     | 0.801     | Top 6%      |
| 融合模型 | 3000+ | 0.833     | Top 3%      |

## 7. 分析與反思
- 精簡特徵反而提升穩定性與泛化能力
- 再平衡處理改善 recall，但可能降低 precision
- 可延伸為回歸問題或結合時間窗做持股建議

> 📌 本檔案僅記錄技術流程，資料內容因比賽規範不予公開。

